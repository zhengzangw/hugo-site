---
title: History
date: 2019-04-14
tags: [ml, math, notes]
weight: 0.1
---

## 神经网络发展史

* 第一阶段
    * 1943年, McCulloch 和 Pitts 提出第一个神经元数学模型, 即 M-P 模型, 并从原理上证明了**人工神经网络能够计算任何算数和逻辑函数**
    * 1949年, Hebb 发表《The Organization of Behavior》一 书, 提出生物神经元学习的机理, 即 **Hebb 学习规则**
    * 1958年, Rosenblatt 提出**感知机网络**(Perceptron)模型和其学习规则
    * 1960年, Widrow和Hoff提出**自适应线性神经元**(Adaline)模型和最小均方学习算法
    * 1969年, Minsky 和Papert 发表《Perceptrons》一书, 指出单层神经网路不能解决非线性问题, 多层网络的训练算法尚无希望. 这个论断导致神经网络进入**低谷**
* 第二阶段
    * 1982年, 物理学家 Hopfield 提出了一种具有联想记忆、优化计算能力的递归网络模型, 即 **Hopfield 网络**
    * 1986年, Rumelhart 等编辑的著作《Parallel Distributed Proceesing: Explorations in the Microstructures of Cognition》报告了**反向传播算法**
    * 1987年, IEEE 在美国加州圣地亚哥召开第一届神经网络国际会议(ICNN)
    * 90年代初, 伴随统计学习理论和SVM的兴起, 神经网络由于理论不够清楚, 试错性强, 难以训练, 再次进入**低谷**
* 第三阶段
    * 2006年, Hinton 提出了**深度信念网络**(DBN), 通过“预训练+微调”使得深 度模型的最优化变得相对容易
    * 2012年, Hinton 组参加 ImageNet 竞赛, 使用 **CNN 模型**以超过第二名10 个百分点的成绩夺得当年竞赛的冠军
    * 伴随云计算、大数据时代的到来，计算能力的大幅提升，使得深度学习模型在计算机视觉、自然语言处理、语音识别等众多领域都取得了较大的成功

## 技术浪潮

|            | 神经网络 | 支持向量机           | 神经网络 |
| ---------- | -------- | -------------------- | -------- |
| 年份       | 89-94    | 95-05                | 06-      |
| 代表性技术 | BP算法   | 核方法，统计学习理论 | 深度学习 |

## 生成式与判别式


|                | 判别式(discriminative)                    | 生成式(generative)                         |
| -------------- | ----------------------------------------- | ------------------------------------------ |
|                | 对 $P(c\vert x)$ 建模                     | 对 $P(c \vert x)=\frac{P(x,c)}{P(x)}$ 建模 |
| 实例           | 决策树，BP 神经网络，SVM                  | 贝叶斯分类器                               |
| 实际环境中问题 | i.i.d. 改变，concept driven，后验概率不变 |                                            |
|                | 没有做“多余”工作                          | 做了“多余”工作                             |